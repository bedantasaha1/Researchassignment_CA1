{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = pd.read_csv(\"matches.csv\")\n",
    "score_df = pd.read_csv(\"deliveries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs and wickets per over #\n",
    "score_df = pd.merge(score_df, match_df[['id','season', 'toss_winner','winner', 'result', 'dl_applied', 'team1', 'team2','venue']], left_on='match_id', right_on='id')\n",
    "score_df.player_dismissed.fillna(0, inplace=True)\n",
    "\n",
    "score_df=score_df.loc[(score_df['venue']=='Eden Gardens')|(score_df['venue']=='Wankhede Stadium')|(score_df['venue']=='Rajiv Gandhi International Stadium, Uppal')|(score_df['venue']=='Maharashtra Cricket Association Stadium')|(score_df['venue']=='Saurashtra Cricket Association Stadium')|(score_df['venue']=='Holkar Cricket Stadium')|(score_df['venue']=='M Chinnaswamy Stadium')|(score_df['venue']=='Feroz Shah Kotla')|(score_df['venue']=='Punjab Cricket Association IS Bindra Stadium, Mohali')|(score_df['venue']=='Green Park')]\n",
    "\n",
    "#score_df=score_df.loc[score_df.over==15,:]\n",
    "score_df['player_dismissed'].loc[score_df['player_dismissed'] != 0] = 1\n",
    "train_df = score_df.groupby(['match_id', 'inning', 'over', 'team1', 'team2', 'venue','batting_team','toss_winner', 'winner'])[['total_runs', 'player_dismissed']].agg(['sum']).reset_index()\n",
    "train_df.columns = train_df.columns.get_level_values(0)\n",
    "\n",
    "# innings score and wickets #\n",
    "train_df['innings_wickets'] = train_df.groupby(['match_id', 'inning'])['player_dismissed'].cumsum()\n",
    "train_df['innings_score'] = train_df.groupby(['match_id', 'inning'])['total_runs'].cumsum()\n",
    "train_df.head()\n",
    "\n",
    "# Get the target column #\n",
    "temp_df = train_df.groupby(['match_id', 'inning'])['total_runs'].sum().reset_index()\n",
    "temp_df = temp_df.loc[temp_df['inning']==1,:]\n",
    "temp_df['inning'] = 2\n",
    "temp_df.columns = ['match_id', 'inning', 'score_target']\n",
    "train_df = train_df.merge(temp_df, how='left', on = ['match_id', 'inning'])\n",
    "train_df['score_target'].fillna(-1, inplace=True)\n",
    "\n",
    "# get the remaining target #\n",
    "def get_remaining_target(row):\n",
    "    if row['score_target'] == -1.:\n",
    "        return -1\n",
    "    else:\n",
    "        return row['score_target'] - row['innings_score']\n",
    "\n",
    "train_df['remaining_target'] = train_df.apply(lambda row: get_remaining_target(row),axis=1)\n",
    "\n",
    "# get the run rate #\n",
    "train_df['run_rate'] = train_df['innings_score'] / train_df['over']\n",
    "\n",
    "# get the remaining run rate #\n",
    "def get_required_rr(row):\n",
    "    if row['remaining_target'] == -1:\n",
    "        return -1.\n",
    "    elif row['over'] == 20:\n",
    "        return 99\n",
    "    else:\n",
    "        return row['remaining_target'] / (20-row['over'])\n",
    "\n",
    "train_df['required_run_rate'] = train_df.apply(lambda row: get_required_rr(row), axis=1)\n",
    "\n",
    "def get_rr_diff(row):\n",
    "    if row['inning'] == 1:\n",
    "        return -1\n",
    "    else:\n",
    "        return row['run_rate'] - row['required_run_rate']\n",
    "\n",
    "train_df['runrate_diff'] = train_df.apply(lambda row: get_rr_diff(row), axis=1)\n",
    "train_df['is_toss_winner_bat_first'] = (train_df['team1'] == train_df['toss_winner']).astype('int')\n",
    "train_df['is_batting_team'] = (train_df['team1'] == train_df['batting_team']).astype('int')\n",
    "train_df['target'] = (train_df['team1'] == train_df['winner']).astype('int')\n",
    "# Get the score_total column for the final score after 1st inning #\n",
    "temp_df = train_df.groupby(['match_id', 'inning'])['total_runs'].sum().reset_index()\n",
    "temp_df = temp_df.loc[temp_df['inning']==1,:]\n",
    "temp_df['inning'] = 1\n",
    "temp_df.columns = ['match_id', 'inning', 'score_total']\n",
    "train_df = train_df.merge(temp_df, how='left', on = ['match_id', 'inning'])\n",
    "train_df['score_total'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Correlation Matrix Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(train_df.corr(),linewidths=0.25,vmax=1.0,square=True,cmap=\"YlGnBu\",linecolor='w',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis to find the Final Score of the 1st Inning after every second Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1st=train_df.loc[train_df.is_batting_team==1,:] #selecting only the 1st innings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix and Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(train_1st.corr(),linewidths=0.25,vmax=1.0,square=True,cmap=\"YlGnBu\",linecolor='w',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Over--------rmse----------Accuracy Percentage---------Predicted Score--------Actual Score')\n",
    "import random\n",
    "n=random.randint(0,57) #selecting a random match of 2017 season\n",
    "PercentageList=[]\n",
    "OverList=[]\n",
    "y_pred_list=[]\n",
    "y_test_list=[]\n",
    "rmse_List=[]\n",
    "for i in range(2,19,2):\n",
    "    test_df = train_1st.loc[train_df.match_id<=59,:] #testing dataset\n",
    "    train_train_df = train_1st.loc[train_df.match_id>59,:] #training dataset\n",
    "    x_train=train_train_df.iloc[:,[2,5,9,10,11,12,15,18,20]].values #selecting the attributes for training data\n",
    "    \n",
    "    #Encoding 'venue' of training data\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_train[:, 1] = labelencoder_X.fit_transform(x_train[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_train = onehotencoder.fit_transform(x_train).toarray()\n",
    "    y_train=train_train_df.iloc[:,21].values #selecting the output column for training data\n",
    "    x_test=test_df.loc[test_df.over==i,:,] #fitting over\n",
    "    x_test=x_test.iloc[:,[2,5,9,10,11,12,15,18,20]].values #selecting the attributes for testing data\n",
    "    \n",
    "    #Encoding 'venue' of testing data\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_test[:, 1] = labelencoder_X.fit_transform(x_test[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_test = onehotencoder.fit_transform(x_test).toarray()\n",
    "    y_test=test_df.loc[test_df.over==i,:,]\n",
    "    y_test=y_test.iloc[:,21].values\n",
    "    \n",
    "    # Feature Scaling of the attributes\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "\n",
    "    # Fitting Multiple Linear Regression to the Training set\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    regressor= LinearRegression()\n",
    "    regressor.fit(x_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = regressor.predict(x_test)\n",
    "\n",
    "    p=(np.mean(1-abs(y_pred-y_test)/y_test)*100) #average accuracy percentage\n",
    "    rmse = np.around(np.sqrt(np.mean((y_test - y_pred)**2))) #average rmse\n",
    "    \n",
    "    PercentageList.append(p)\n",
    "    rmse_List.append(rmse)\n",
    "    OverList.append(i)\n",
    "    y_p=y_pred[n] #Predicted final score of any random match\n",
    "    y_t=y_test[n] #Actual final score of any random match\n",
    "    print(i,'------',rmse,'-------',p, '----------',y_p,'------------', y_t)\n",
    "    y_pred_list.append(y_p) \n",
    "    y_test_list.append(y_t)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy Percentage bar graph\n",
    "OverPerDict=dict(zip(OverList,PercentageList))\n",
    "OverPerDic_df=pd.Series(OverPerDict, name='Percentage')\n",
    "OverPerDic_df.index.name = 'Over'\n",
    "Over_df=OverPerDic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "a=alt.Chart(Over_df).mark_bar().encode(\n",
    "    x='Over',\n",
    "    y='Percentage'\n",
    ").properties(\n",
    "    title='Overwise average accuracy to predict average final score after 20th over in the 1st innings using MLR'\n",
    ")\n",
    "\n",
    "#Average predicted final score line graph\n",
    "y_pred_Dict=dict(zip(OverList,y_pred_list))\n",
    "y_pred_Dic_df=pd.Series(y_pred_Dict, name='Predicted Value')\n",
    "y_pred_Dic_df.index.name = 'Over'\n",
    "y_pred_df=y_pred_Dic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "b=alt.Chart(y_pred_df).mark_line().encode(\n",
    "    x='Over',\n",
    "    y='Predicted Value'\n",
    ")\n",
    "\n",
    "# Average actual final score line graph\n",
    "y_test_Dict=dict(zip(OverList,y_test_list))\n",
    "y_test_Dic_df=pd.Series(y_test_Dict, name='Actual Value')\n",
    "y_test_Dic_df.index.name = 'Over'\n",
    "y_test_df=y_test_Dic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "c=alt.Chart(y_test_df).mark_line(color='red').encode(\n",
    "    x='Over',\n",
    "    y='Actual Value'\n",
    ")\n",
    "d=(b+c).properties(\n",
    "    title='Overwise predicted score(Blue) using MLR and the actual score(Red) after 20th Over of a randomly selected match'\n",
    ")\n",
    "\n",
    "# Average rmse deviation from final score bar graph\n",
    "rmse_Dict=dict(zip(OverList,rmse_List))\n",
    "rmse_Dic_df=pd.Series(rmse_Dict, name='rmse')\n",
    "rmse_Dic_df.index.name = 'Over'\n",
    "rmse_df=rmse_Dic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "e=alt.Chart(rmse_df).mark_line().encode(\n",
    "    x='Over',\n",
    "    y='rmse'\n",
    ").properties(\n",
    "    title='Overwise average rmse deviation from the predicted and actual final score of MLR'\n",
    ")\n",
    "a|d|e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Over--------rmse----------Accuracy Percentage---------Predicted Score--------Actual Score')\n",
    "PercentageList=[]\n",
    "OverList=[]\n",
    "y_pred_list=[]\n",
    "y_test_list=[]\n",
    "rmse_List=[]\n",
    "for i in range(2,19,2):\n",
    "    test_df = train_1st.loc[train_df.match_id<=59,:] #testing dataset\n",
    "    train_train_df = train_1st.loc[train_df.match_id>59,:] #training dataset\n",
    "    x_train=train_train_df.iloc[:,[2,5,9,10,11,12,15,18,20]].values #selecting the attributes for training data\n",
    "    \n",
    "    #Encoding 'venue' of training data\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_train[:, 1] = labelencoder_X.fit_transform(x_train[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_train = onehotencoder.fit_transform(x_train).toarray()\n",
    "    y_train=train_train_df.iloc[:,21].values #selecting the output column for training data\n",
    "    x_test=test_df.loc[test_df.over==i,:,] #fitting over\n",
    "    x_test=x_test.iloc[:,[2,5,9,10,11,12,15,18,20]].values #selecting the attributes for testing data\n",
    "    \n",
    "    #Encoding 'venue' of testing data\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_test[:, 1] = labelencoder_X.fit_transform(x_test[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_test = onehotencoder.fit_transform(x_test).toarray()\n",
    "    y_test=test_df.loc[test_df.over==i,:,]\n",
    "    y_test=y_test.iloc[:,21].values\n",
    "    \n",
    "    # Feature Scaling of the attributes\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "\n",
    "\n",
    "    # Fitting Random Forest Regression to the Training Set\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    regressor = RandomForestRegressor(n_estimators=250,random_state=0)\n",
    "    regressor.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = regressor.predict(x_test)\n",
    "\n",
    "    p=(np.mean(1-abs(y_pred-y_test)/y_test)*100) #average accuracy percentage\n",
    "    rmse = np.around(np.sqrt(np.mean((y_test - y_pred)**2))) #average rmse\n",
    "    print(i,'------',rmse,'-------',p, '----------',y_p,'------------', y_t)\n",
    "    PercentageList.append(p)\n",
    "    rmse_List.append(rmse)\n",
    "    OverList.append(i)\n",
    "    y_p=y_pred[n]# predicted final score of any random match\n",
    "    y_t=y_test[n] #actual final score of any random match\n",
    "    y_pred_list.append(y_p) \n",
    "    y_test_list.append(y_t)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy Percentage bar graph\n",
    "OverPerDict=dict(zip(OverList,PercentageList))\n",
    "OverPerDic_df=pd.Series(OverPerDict, name='Percentage')\n",
    "OverPerDic_df.index.name = 'Over'\n",
    "Over_df=OverPerDic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "a=alt.Chart(Over_df).mark_bar().encode(\n",
    "    x='Over',\n",
    "    y='Percentage'\n",
    ").properties(\n",
    "    title='Overwise average accuracy to predict average final score after 20th over in the 1st innings using RFR'\n",
    ")\n",
    "\n",
    "#Average predicted final score line graph\n",
    "y_pred_Dict=dict(zip(OverList,y_pred_list))\n",
    "y_pred_Dic_df=pd.Series(y_pred_Dict, name='Predicted Value')\n",
    "y_pred_Dic_df.index.name = 'Over'\n",
    "y_pred_df=y_pred_Dic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "b=alt.Chart(y_pred_df).mark_line().encode(\n",
    "    x='Over',\n",
    "    y='Predicted Value'\n",
    ")\n",
    "\n",
    "# Average actual final score line graph\n",
    "y_test_Dict=dict(zip(OverList,y_test_list))\n",
    "y_test_Dic_df=pd.Series(y_test_Dict, name='Actual Value')\n",
    "y_test_Dic_df.index.name = 'Over'\n",
    "y_test_df=y_test_Dic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "c=alt.Chart(y_test_df).mark_line(color='red').encode(\n",
    "    x='Over',\n",
    "    y='Actual Value'\n",
    ")\n",
    "d=(b+c).properties(\n",
    "    title='Overwise predicted score(Blue) using RFR and the actual score(Red) after 20th Over of a randomly selected match'\n",
    ")\n",
    "\n",
    "# Average rmse deviation from final score bar graph\n",
    "rmse_Dict=dict(zip(OverList,rmse_List))\n",
    "rmse_Dic_df=pd.Series(rmse_Dict, name='rmse')\n",
    "rmse_Dic_df.index.name = 'Over'\n",
    "rmse_df=rmse_Dic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "e=alt.Chart(rmse_df).mark_line().encode(\n",
    "    x='Over',\n",
    "    y='rmse'\n",
    ").properties(\n",
    "    title='Overwise average rmse deviation from the predicted and actual final score of RFR'\n",
    ")\n",
    "a|d|e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Over--------rmse----------Accuracy Percentage---------Predicted Score--------Actual Score')\n",
    "PercentageList=[]\n",
    "OverList=[]\n",
    "y_pred_list=[]\n",
    "y_test_list=[]\n",
    "rmse_List=[]\n",
    "for i in range(2,19,2):\n",
    "    test_df = train_1st.loc[train_df.match_id<=59,:] #testing dataset\n",
    "    train_train_df = train_1st.loc[train_df.match_id>59,:] #training dataset\n",
    "    x_train=train_train_df.iloc[:,[2,5,9,10,11,12,15,18,20]].values #selecting the attributes for training data\n",
    "    \n",
    "    #Encoding 'venue' of training data\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_train[:, 1] = labelencoder_X.fit_transform(x_train[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_train = onehotencoder.fit_transform(x_train).toarray()\n",
    "    y_train=train_train_df.iloc[:,21].values #selecting the output column for training data\n",
    "    x_test=test_df.loc[test_df.over==i,:,] #fitting over\n",
    "    x_test=x_test.iloc[:,[2,5,9,10,11,12,15,18,20]].values #selecting the attributes for testing data\n",
    "    \n",
    "    #Encoding 'venue' of testing data\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_test[:, 1] = labelencoder_X.fit_transform(x_test[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_test = onehotencoder.fit_transform(x_test).toarray()\n",
    "    y_test=test_df.loc[test_df.over==i,:,] #fitting over\n",
    "    y_test=y_test.iloc[:,21].values\n",
    "    \n",
    "    # Feature Scaling of the attributes\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "\n",
    "    #Fitting Support Vector Regression to the training set\n",
    "    from sklearn.svm import SVR\n",
    "    regressor=SVR(kernel='linear')\n",
    "    regressor.fit(x_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = regressor.predict(x_test)\n",
    "\n",
    "    p=(np.mean(1-abs(y_pred-y_test)/y_test)*100) #average accuracy percentage\n",
    "    rmse = np.around(np.sqrt(np.mean((y_test - y_pred)**2))) #average rmse\n",
    "    print(i,'------',rmse,'-------',p, '----------',y_p,'------------', y_t)\n",
    "    PercentageList.append(p)\n",
    "    rmse_List.append(rmse)\n",
    "    OverList.append(i)\n",
    "    y_p=y_pred[n] #predicted final score of any random match\n",
    "    y_t=y_test[n] #predicted final score of any random match\n",
    "    y_pred_list.append(y_p) \n",
    "    y_test_list.append(y_t)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy Percentage bar graph\n",
    "OverPerDict=dict(zip(OverList,PercentageList))\n",
    "OverPerDic_df=pd.Series(OverPerDict, name='Percentage')\n",
    "OverPerDic_df.index.name = 'Over'\n",
    "Over_df=OverPerDic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "a=alt.Chart(Over_df).mark_bar().encode(\n",
    "    x='Over',\n",
    "    y='Percentage'\n",
    ").properties(\n",
    "    title='Overwise average accuracy to predict average final score after 20th over in the 1st innings using SVR'\n",
    ")\n",
    "\n",
    "#Average predicted final score line graph\n",
    "y_pred_Dict=dict(zip(OverList,y_pred_list))\n",
    "y_pred_Dic_df=pd.Series(y_pred_Dict, name='Predicted Value')\n",
    "y_pred_Dic_df.index.name = 'Over'\n",
    "y_pred_df=y_pred_Dic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "b=alt.Chart(y_pred_df).mark_line().encode(\n",
    "    x='Over',\n",
    "    y='Predicted Value'\n",
    ")\n",
    "\n",
    "# Average actual final score line graph\n",
    "y_test_Dict=dict(zip(OverList,y_test_list))\n",
    "y_test_Dic_df=pd.Series(y_test_Dict, name='Actual Value')\n",
    "y_test_Dic_df.index.name = 'Over'\n",
    "y_test_df=y_test_Dic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "c=alt.Chart(y_test_df).mark_line(color='red').encode(\n",
    "    x='Over',\n",
    "    y='Actual Value'\n",
    ")\n",
    "d=(b+c).properties(\n",
    "    title='Overwise predicted score(Blue) using SVR and the actual score(Red) after 20th Over of any randomly selected match'\n",
    ")\n",
    "\n",
    "# Average rmse deviation from final score bar graph\n",
    "rmse_Dict=dict(zip(OverList,rmse_List))\n",
    "rmse_Dic_df=pd.Series(rmse_Dict, name='rmse')\n",
    "rmse_Dic_df.index.name = 'Over'\n",
    "rmse_df=rmse_Dic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "e=alt.Chart(rmse_df).mark_line().encode(\n",
    "    x='Over',\n",
    "    y='rmse'\n",
    ").properties(\n",
    "    title='Overwise average rmse deviation from the predicted and actual final score of SVR'\n",
    ")\n",
    "a|d|e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification for match winner prediction after every second over of 2nd inning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1st=train_df.loc[train_df.is_batting_team==0,:] #selecting only the second innings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix and Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(train_1st.corr(),linewidths=0.25,vmax=1.0,square=True,cmap=\"YlGnBu\",linecolor='w',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Over-------------Precision')\n",
    "PrecisionList=[]\n",
    "OverList=[]\n",
    "for i in range(2,19,2):\n",
    "    test_df = train_1st.loc[train_df.match_id<=59,:] #Testing Dataset\n",
    "    train_train_df = train_1st.loc[train_df.match_id>50,:] #Training Dataset\n",
    "    x_train=train_train_df.iloc[:,[2,5,9,10,11,12,13,15,16,18]].values #selecting attributes for training data\n",
    "    \n",
    "    #Encoding 'venue' of training data\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_train[:, 1] = labelencoder_X.fit_transform(x_train[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_train = onehotencoder.fit_transform(x_train).toarray()\n",
    "    y_train=train_train_df.iloc[:,20].values #Selecting the output column for training data\n",
    "    x_test=test_df.loc[test_df.over==i,:,]#fitting the over\n",
    "    x_test=x_test.iloc[:,[2,5,9,10,11,12,13,15,16,18]].values #selecting attributes for testing data\n",
    "    \n",
    "    #Encoding 'venue' of testing data\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_test[:, 1] = labelencoder_X.fit_transform(x_test[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_test = onehotencoder.fit_transform(x_test).toarray()\n",
    "    y_test=test_df.loc[test_df.over==i,:,]#fitting the over\n",
    "    y_test=y_test.iloc[:,20].values #Selecting the output column for training data\n",
    "    \n",
    "    # Feature Scaling of the attributes\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    \n",
    "    #Fitting Random Forest Classifier to the training set\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators=250,criterion='entropy',random_state=0)\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    p=(cm[0,0]+cm[1,1])/(cm[0,1]+cm[1,0]+cm[0,0]+cm[1,1])*100 #Calculating Precision \n",
    "    from sklearn.metrics import classification_report\n",
    "    cr=classification_report(y_test, y_pred) #Calculating Classification Report\n",
    "    #print('Classification Report after over: ',i)\n",
    "    #print(cr)\n",
    "    print(i,'-------------',p)\n",
    "    PrecisionList.append(p)\n",
    "    OverList.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision Percentage bar graph\n",
    "OverPerDict=dict(zip(OverList,PrecisionList))\n",
    "OverPerDic_df=pd.Series(OverPerDict, name='Precision')\n",
    "OverPerDic_df.index.name = 'Over'\n",
    "Over_df=OverPerDic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "a=alt.Chart(Over_df).mark_bar().encode(\n",
    "    x='Over',\n",
    "    y='Precision'\n",
    ").properties(\n",
    "    title='Overwise average precision to predict the winnerin the 2nd innings using RFC'\n",
    ")\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def rocAucCurve(classifier):\n",
    "    logit_roc_auc = roc_auc_score(y_test, classifier.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Random Forest Classification (area = %0.2f)' % logit_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Match winning prediction charactaristic using RFC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()\n",
    "b=rocAucCurve(classifier)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Over-------------Precision')\n",
    "PrecisionList=[]\n",
    "OverList=[]\n",
    "for i in range(2,19,2):\n",
    "    test_df = train_1st.loc[train_df.match_id<=59,:] #Testing Dataset\n",
    "    train_train_df = train_1st.loc[train_df.match_id>50,:] #Training Dataset\n",
    "    x_train=train_train_df.iloc[:,[2,5,9,10,11,12,13,15,16,18]].values #selecting attributes for training data\n",
    "    \n",
    "    #Encoding 'venue' of training data\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_train[:, 1] = labelencoder_X.fit_transform(x_train[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_train = onehotencoder.fit_transform(x_train).toarray()\n",
    "    y_train=train_train_df.iloc[:,20].values #Selecting the output column for training data\n",
    "    x_test=test_df.loc[test_df.over==i,:,]#fitting the over\n",
    "    x_test=x_test.iloc[:,[2,5,9,10,11,12,13,15,16,18]].values #selecting attributes for testing data\n",
    "    \n",
    "    #Encoding 'venue' of testing data\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_test[:, 1] = labelencoder_X.fit_transform(x_test[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_test = onehotencoder.fit_transform(x_test).toarray()\n",
    "    y_test=test_df.loc[test_df.over==i,:,]#fitting the over\n",
    "    y_test=y_test.iloc[:,20].values #Selecting the output column for training data\n",
    "    \n",
    "    # Feature Scaling of the attributes\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    \n",
    "    #Fitting Support Vector Machine to the training set\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'poly', random_state = 0, probability=True)\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    p=(cm[0,0]+cm[1,1])/(cm[0,1]+cm[1,0]+cm[0,0]+cm[1,1])*100 #Calculating Precision \n",
    "    from sklearn.metrics import classification_report\n",
    "    cr=classification_report(y_test, y_pred) #Calculating Classification Report\n",
    "    #print('Classification Report after over: ',i)\n",
    "    #print(cr)\n",
    "    print(i,'-------------',p)\n",
    "    PrecisionList.append(p)\n",
    "    OverList.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision Percentage bar graph\n",
    "OverPerDict=dict(zip(OverList,PrecisionList))\n",
    "OverPerDic_df=pd.Series(OverPerDict, name='Precision')\n",
    "OverPerDic_df.index.name = 'Over'\n",
    "Over_df=OverPerDic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "a=alt.Chart(Over_df).mark_bar().encode(\n",
    "    x='Over',\n",
    "    y='Precision'\n",
    ").properties(\n",
    "    title='Overwise average precision to predict the winnerin the 2nd innings using SVM'\n",
    ")\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def rocAucCurve(classifier):\n",
    "    logit_roc_auc = roc_auc_score(y_test, classifier.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Support Vector Machine (area = %0.2f)' % logit_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Match winning prediction charactaristic with SVM')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()\n",
    "b=rocAucCurve(classifier)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Over-------------Precision')\n",
    "PrecisionList=[]\n",
    "OverList=[]\n",
    "for i in range(2,19,2):\n",
    "    test_df = train_1st.loc[train_df.match_id<=59,:] #Testing Dataset\n",
    "    train_train_df = train_1st.loc[train_df.match_id>50,:] #Training Dataset\n",
    "    x_train=train_train_df.iloc[:,[2,5,9,10,11,12,13,15,16,18]].values #selecting attributes for training data\n",
    "    \n",
    "    #Encoding 'venue' of training data\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_train[:, 1] = labelencoder_X.fit_transform(x_train[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_train = onehotencoder.fit_transform(x_train).toarray()\n",
    "    y_train=train_train_df.iloc[:,20].values #Selecting the output column for training data\n",
    "    x_test=test_df.loc[test_df.over==i,:,]#fitting the over\n",
    "    x_test=x_test.iloc[:,[2,5,9,10,11,12,13,15,16,18]].values #selecting attributes for testing data\n",
    "    \n",
    "    #Encoding 'venue' of testing data\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    x_test[:, 1] = labelencoder_X.fit_transform(x_test[:, 1])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    x_test = onehotencoder.fit_transform(x_test).toarray()\n",
    "    y_test=test_df.loc[test_df.over==i,:,]#fitting the over\n",
    "    y_test=y_test.iloc[:,20].values #Selecting the output column for training data\n",
    "    \n",
    "    # Feature Scaling of the attributes\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    \n",
    "    #Fitting K-Nearest Neighbour to the training set\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors=6,metric='minkowski', p=2)\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    p=(cm[0,0]+cm[1,1])/(cm[0,1]+cm[1,0]+cm[0,0]+cm[1,1])*100 #Calculating Precision \n",
    "    from sklearn.metrics import classification_report\n",
    "    cr=classification_report(y_test, y_pred) #Calculating Classification Report\n",
    "    #print('Classification Report after over: ',i)\n",
    "    #print(cr)\n",
    "    print(i,'-------------',p)\n",
    "    PrecisionList.append(p)\n",
    "    OverList.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision Percentage bar graph\n",
    "OverPerDict=dict(zip(OverList,PrecisionList))\n",
    "OverPerDic_df=pd.Series(OverPerDict, name='Precision')\n",
    "OverPerDic_df.index.name = 'Over'\n",
    "Over_df=OverPerDic_df.reset_index()\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "alt.renderers.enable('notebook')\n",
    "a=alt.Chart(Over_df).mark_bar().encode(\n",
    "    x='Over',\n",
    "    y='Precision'\n",
    ").properties(\n",
    "    title='Overwise average precision to predict the winnerin the 2nd innings using KNN'\n",
    ")\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def rocAucCurve(classifier):\n",
    "    logit_roc_auc = roc_auc_score(y_test, classifier.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='K-Nearest Neighbor (area = %0.2f)' % logit_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Match winning prediction charactaristic with KNN')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()\n",
    "b=rocAucCurve(classifier)\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
